{"nbformat_minor": 0, "cells": [{"source": "#Perceptual Intelligence in Cortana Analytics\n###*Exploring the Microsoft Project Oxford Face API*\n\n[Face API site](https://www.projectoxford.ai/face)\n[Face API reference](https://dev.projectoxford.ai/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236)\n\n\n<img src=\"https://raw.githubusercontent.com/deldersveld/CortanaAnalyticsLabs/master/PerceptualIntelligence/Images/ThumbsUp.png\" width=\"200\">\n\nIn this activity, you will use Python to explore various methods available from the Face API. \nYou will detect a face in an image and crop the image so only the face appears. \nYou will then detect multiple faces in a second image and similarly crop each face.\nAfter getting exposure to detecting faces, you will then create a face list and add five distinct faces to the list.\nFinally, you will use your initial image to find similar faces from your face list.\n\nThis activity uses the following API methods:\n    * Detect\n    * Create a Face List\n    * Get a Face List\n    * Delete a Face List (optional)\n    * Add a Face to a Face List\n    * Find Similar\n    \nAll images are in the public domain.\n", "cell_type": "markdown", "metadata": {}}, {"source": "###Step 1: Enter your Face API key\n\nSubstitute the value of *faceApiSubscriptionKey* with your own API key. \nReplace **[Face API Primary Key]** but leave the quotation marks around your key.\n\nTo obtain your Face API key or sign up for the API, visit the [Subscription page](https://www.projectoxford.ai/Subscription?popup=False).\n\nWhen ready, run the cell, which imports required libraries and sets initial variables.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "import httplib, urllib, base64, json\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\n%matplotlib inline\n\nfaceApiSubscriptionKey = \"[Face API Primary Key]\"\n\nbaseFaceUrl = \"https://raw.githubusercontent.com/CortanaAnalyticsLabs/\\\nCortanaAnalyticsLabs/master/PerceptualIntelligence/Images/\"\n\nthumbsUp = baseFaceUrl + \"ThumbsUp.png\"\nmultipleFaces = baseFaceUrl + \"MultipleFaces.png\"\nfaceA = baseFaceUrl + \"FaceA.png\"\nfaceB = baseFaceUrl + \"FaceB.png\"\nfaceC = baseFaceUrl + \"FaceC.png\"\nfaceD = baseFaceUrl + \"FaceD.png\"\nfaceE = baseFaceUrl + \"FaceE.png\"\n\nprint(\"Initialization complete\")", "outputs": [], "metadata": {"collapsed": false}}, {"source": "###Step 2: Define functions\n\nThe following five functions allow you to pass your API key and other relevant parameters based on the API reference.\nRun the cell to create the various functions.\n    * detect(apiKey, imageUrl)\n    * createFaceList(apiKey, faceListId)\n    * getFaceList(apiKey, faceListId)\n    * deleteFaceList(apiKey, faceListId)\n    * addFaceToFaceList(apiKey, faceListId, imageUrl)\n    * findSimilars(apiKey, faceListId, faceId, numberOfCandidates)", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def detect(apiKey, imageUrl):\n    jsonBody = '{\"url\":\"' + imageUrl + '\"}'\n\n    headers = {\n        'Content-Type': 'application/json',\n        'Ocp-Apim-Subscription-Key': apiKey,\n    }\n\n    params = urllib.urlencode({\n        'returnFaceId': 'true',\n        'returnFaceLandmarks': 'false',\n        'returnFaceAttributes': 'age,gender',\n    })\n\n    try:\n        conn = httplib.HTTPSConnection('api.projectoxford.ai')\n        conn.request(\"POST\", \"/face/v1.0/detect?%s\" % params, jsonBody, headers)\n        response = conn.getresponse()\n        data = response.read()\n        print(data)\n        conn.close()\n    except Exception as e:\n        print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))\n        \n    return data\n\ndef createFaceList(apiKey, faceListId):\n    faceList = faceListId\n    jsonBody = '{\"name\":\"' + faceList + '\", \"userData\":\"User-provided data attached to the face list\"}'\n    \n    headers = {\n        'Content-Type': 'application/json',\n        'Ocp-Apim-Subscription-Key': apiKey,\n    }\n\n    params = urllib.urlencode({\n    })\n\n    try:\n        conn = httplib.HTTPSConnection('api.projectoxford.ai')\n        conn.request(\"PUT\", \"/face/v1.0/facelists/\" + faceList + \"?%s\" % params, jsonBody, headers)\n        response = conn.getresponse()\n        data = response.read()\n        print(data)\n        conn.close()\n    except Exception as e:\n        print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))\n        \ndef getFaceList(apiKey, faceListId):\n    faceList = faceListId\n    jsonBody = ''\n    \n    headers = {\n        'Ocp-Apim-Subscription-Key': apiKey,\n    }\n\n    params = urllib.urlencode({\n    })\n\n    try:\n        conn = httplib.HTTPSConnection('api.projectoxford.ai')\n        conn.request(\"GET\", \"/face/v1.0/facelists/\" + faceList + \"?%s\" % params, jsonBody, headers)\n        response = conn.getresponse()\n        data = response.read()\n        print(data)\n        conn.close()\n    except Exception as e:\n        print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))\n        \ndef deleteFaceList(apiKey, faceListId):\n    faceList = faceListId\n    jsonBody = ''\n    \n    headers = {\n        'Ocp-Apim-Subscription-Key': apiKey,\n    }\n\n    params = urllib.urlencode({\n    })\n\n    try:\n        conn = httplib.HTTPSConnection('api.projectoxford.ai')\n        conn.request(\"DELETE\", \"/face/v1.0/facelists/\" + faceList + \"%s\" % params, jsonBody, headers)\n        response = conn.getresponse()\n        data = response.read()\n        print(data)\n        conn.close()\n    except Exception as e:\n        print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))\n        \ndef addFaceToFaceList(apiKey, faceListId, imageUrl):\n    faceList = faceListId\n    jsonBody = '{\"url\":\"' + imageUrl + '\"}'\n    \n    headers = {\n        'Content-Type': 'application/json',\n        'Ocp-Apim-Subscription-Key': apiKey,\n    }\n\n    params = urllib.urlencode({\n    })\n\n    try:\n        conn = httplib.HTTPSConnection('api.projectoxford.ai')\n        conn.request(\"POST\", \"/face/v1.0/facelists/\" + faceList + \"/persistedFaces?%s\" % params, jsonBody, headers)\n        response = conn.getresponse()\n        data = response.read()\n        print(data)\n        conn.close()\n    except Exception as e:\n        print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))\n        \ndef findSimilars(apiKey, faceListId, faceId, numberOfCandidates):\n    jsonBody = '{\"faceId\":\"' + faceId + '\", \\\n                \"faceListId\":\"' + faceListId + '\", \\\n                \"maxNumOfCandidatesReturned\":' + numberOfCandidates + '}'\n    headers = {\n        'Content-Type': 'application/json',\n        'Ocp-Apim-Subscription-Key': apiKey,\n    }\n\n    params = urllib.urlencode({\n    })\n\n    try:\n        conn = httplib.HTTPSConnection('api.projectoxford.ai')\n        conn.request(\"POST\", \"/face/v1.0/findsimilars?%s\" % params, jsonBody, headers)\n        response = conn.getresponse()\n        data = response.read()\n        print(data)\n        conn.close()\n    except Exception as e:\n        print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))\n        \nprint(\"API functions created\")", "outputs": [], "metadata": {"collapsed": false}}, {"source": "###Step 3: Display the initial image\n\nRun the following cell to display the image of a person. The image also displays pixels along the two axes.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "img = mpimg.imread(thumbsUp)\nplt.imshow(img)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "###Step 4: Detect the face on the initial image\n\nRun the following cell to call the *detect* method, which returns a face box for the image. Note the values of \"top\" and \"left\" in \"faceRectangle\" and compare that point to the axes on the original image. The face rectangle then defines a box using the appropriate \"width\" and \"height\" values starting from that point. In addition, gender and age are displayed as attributes.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "thumbsUpData = detect(faceApiSubscriptionKey, thumbsUp)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "###Step 5: Crop the face\n\nRun the following cell to take the JSON returned by the API and display only the faceRectangle", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "face = json.loads(thumbsUpData)\nthumbsUpFaceId = face[0][\"faceId\"]\nfaceTop = face[0][\"faceRectangle\"][\"top\"]\nfaceLeft = face[0][\"faceRectangle\"][\"left\"]\nfaceWidth = face[0][\"faceRectangle\"][\"width\"]\nfaceHeight = face[0][\"faceRectangle\"][\"height\"]\n\nimg = mpimg.imread(thumbsUp)\nplt.imshow(img[faceTop:faceTop + faceHeight, faceLeft:faceLeft + faceWidth])", "outputs": [], "metadata": {"collapsed": false}}, {"source": "###Step 6: Detect multiple faces in an image\n\nRun the following cells in sequence to display an image with multiple faces, call the API to detect faces, and display the results. Note that while there are *three* people in the image, the API only returns two faces due to the side-facing orientation of the third person.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "img = mpimg.imread(multipleFaces)\nplt.imshow(img)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "multipleFacesData = detect(faceApiSubscriptionKey, multipleFaces)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "face = json.loads(multipleFacesData)\nfaceTop = face[0][\"faceRectangle\"][\"top\"]\nfaceLeft = face[0][\"faceRectangle\"][\"left\"]\nfaceWidth = face[0][\"faceRectangle\"][\"width\"]\nfaceHeight = face[0][\"faceRectangle\"][\"height\"]\n\nimg = mpimg.imread(multipleFaces)\nplt.imshow(img[faceTop:faceTop + faceHeight, faceLeft:faceLeft + faceWidth])", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "face = json.loads(multipleFacesData)\nfaceTop = face[1][\"faceRectangle\"][\"top\"]\nfaceLeft = face[1][\"faceRectangle\"][\"left\"]\nfaceWidth = face[1][\"faceRectangle\"][\"width\"]\nfaceHeight = face[1][\"faceRectangle\"][\"height\"]\n\nimg = mpimg.imread(multipleFaces)\nplt.imshow(img[faceTop:faceTop + faceHeight, faceLeft:faceLeft + faceWidth])", "outputs": [], "metadata": {"collapsed": false}}, {"source": "###Step 7: Create a Face List\n\nRun the following cell to create a new face list called \"sample\", then show that the list is empty. \nA Face List is simply a collection of faces that remain unidentified and are referenced by Id. \nThe API also has the ability to create a Person List for known people and call methods to identify new face images based on that list.\nNote that there is also a delete function that is commented out in case you would like to delete and re-create your face list at a later time.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "#deleteFaceList(faceApiSubscriptionKey, \"sample\")\ncreateFaceList(faceApiSubscriptionKey, \"sample\")\ngetFaceList(faceApiSubscriptionKey, \"sample\")", "outputs": [], "metadata": {"collapsed": false}}, {"source": "###Step 8: Add faces to your Face List\n\nRun the following five cells in sequence to display images of five distinct people and load their face information into your face list. Your faces are referenced in the list using \"persistedFaceId\".", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "img = mpimg.imread(faceA)\nplt.imshow(img)\nrawFaceDataA = detect(faceApiSubscriptionKey, faceA)\naddFaceToFaceList(faceApiSubscriptionKey, \"sample\", faceA)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "img = mpimg.imread(faceB)\nplt.imshow(img)\nrawFaceDataB = detect(faceApiSubscriptionKey, faceB)\naddFaceToFaceList(faceApiSubscriptionKey, \"sample\", faceB)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "img = mpimg.imread(faceC)\nplt.imshow(img)\nrawFaceDataC = detect(faceApiSubscriptionKey, faceC)\nfaceDataC = json.loads(rawFaceDataC)\naddFaceToFaceList(faceApiSubscriptionKey, \"sample\", faceC)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "img = mpimg.imread(faceD)\nplt.imshow(img)\nrawFaceDataD = detect(faceApiSubscriptionKey, faceD)\naddFaceToFaceList(faceApiSubscriptionKey, \"sample\", faceD)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "img = mpimg.imread(faceE)\nplt.imshow(img)\nrawFaceDataE = detect(faceApiSubscriptionKey, faceE)\naddFaceToFaceList(faceApiSubscriptionKey, \"sample\", faceE)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "###Step 9: Display contents of your Face List\n\nRun the following cell to display the contents of your recently populated face list. \nWhen you first created the list and called this function, it was empty.\nYou should now see the \"persistedFaceId\" values for the five faces that you added to your list.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "getFaceList(faceApiSubscriptionKey, \"sample\")", "outputs": [], "metadata": {"collapsed": false}}, {"source": "###Step 10: Pass a sample image and find similar faces in your Face List\n\nRun the following cell to compare the initial face of the \"thumbs up woman\" from Step 3 with the five faces in your face list.\nOne result should display with a reasonably high confidence value.\nThe \"thumbs up woman\" and \"woman with apple\" are the same person.\n\n<img src=\"https://raw.githubusercontent.com/deldersveld/CortanaAnalyticsLabs/master/PerceptualIntelligence/Images/ThumbsUp.png\" width=\"200\">\n<img src=\"https://raw.githubusercontent.com/deldersveld/CortanaAnalyticsLabs/master/PerceptualIntelligence/Images/FaceA.png\" width=\"300\">", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "findSimilars(faceApiSubscriptionKey, \"sample\", thumbsUpFaceId, \"5\")", "outputs": [], "metadata": {"collapsed": false}}, {"source": "###Conclusion\n\nYou have completed the Face API lab activity. \nIf you would like more detail about additional capabilities, visit the [Face API reference](https://dev.projectoxford.ai/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236) page.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.11", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}